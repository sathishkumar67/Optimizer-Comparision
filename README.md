Experimenting Diff Optimizers

## Results between Cosine Scheduled Adam optimizer and Schedule Free Adam Optimizer
<img src="assets/Training Loss" width="1000px"></img>
<img src="assets/Cosine Learning rate" width="1000px"></img>

Still experiment have to be made on how schedule free adam optimizer performs in larger traning with larger model
